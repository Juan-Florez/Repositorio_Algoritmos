{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "In base to the implementation provided by the teacher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "\n",
    "    def __init__(self, learning_rate: float, input_size: int):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = np.zeros(input_size)\n",
    "        # We had choose to make bias into his very own variable\n",
    "        self.bias = 0\n",
    "\n",
    "    def train(self, training_data: np.ndarray, binary_class: np.ndarray):\n",
    "        # In this case we update the weights every time we evaluate a data vector\n",
    "        for vector, binary in zip(training_data, binary_class):\n",
    "            delta_error = (binary - self.predict(vector)) * self.learning_rate\n",
    "            self.weights += vector * delta_error\n",
    "            self.bias += delta_error\n",
    "\n",
    "    def test(self, test_data, binary_class):\n",
    "        # A simple test that print the proportion of wrong to right answers in the test data\n",
    "        answer_evaluation = [int(self.predict(vector)) == binary\n",
    "                             for vector, binary in zip(test_data, binary_class)]\n",
    "\n",
    "        summarize = Counter(answer_evaluation)\n",
    "        precision = sum(answer_evaluation) / len(answer_evaluation)\n",
    "\n",
    "        print(f'The test gave {summarize[True]} correct prediction '\n",
    "              + f'and {summarize[False]} wrong prediction '\n",
    "              + f'having a precision of {precision}')\n",
    "\n",
    "    def predict(self, vector):\n",
    "        # A simple dot product of vectors and a sum as predicition\n",
    "        calculation = np.dot(vector, self.weights) + self.bias\n",
    "        return 1 * (calculation > 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Processing\n",
    "\n",
    "We are using the titanic passenger survival dataset provided from [Kaggle](https://www.kaggle.com/competitions/titanic) the dataset includes a serie of characteristics about the passengers and whenever they survived or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  Sex  Age  SibSp  Parch     Fare  Embarked\n",
       "PassengerId                                                             \n",
       "1                   0       3    0   22      1      0   7.2500         1\n",
       "2                   1       1    1   38      1      0  71.2833         3\n",
       "3                   1       3    1   26      0      0   7.9250         1\n",
       "4                   1       1    1   35      1      0  53.1000         1\n",
       "5                   0       3    0   35      0      0   8.0500         1\n",
       "...               ...     ...  ...  ...    ...    ...      ...       ...\n",
       "886                 0       3    1   39      0      5  29.1250         2\n",
       "887                 0       2    0   27      0      0  13.0000         1\n",
       "888                 1       1    1   19      0      0  30.0000         1\n",
       "890                 1       1    0   26      0      0  30.0000         3\n",
       "891                 0       3    0   32      0      0   7.7500         2\n",
       "\n",
       "[712 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('titanic/train.csv')\n",
    "df.set_index('PassengerId', inplace=True)\n",
    "# We get rid of the name, ticket identification and cabin identification\n",
    "# as are string characteristics that we dont know how to handle\n",
    "df.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "# We get rid of all the vextors with non valid data\n",
    "df.dropna(inplace=True)\n",
    "# We map sex to boolean values\n",
    "df.Sex = df.Sex.apply(lambda x: int(x == 'female'))\n",
    "# We map Embarkment to numeric values\n",
    "df.Embarked = df.Embarked.apply(lambda x: {'S': 1, 'Q': 2, 'C': 3}[x])\n",
    "# We turn age into a integer value\n",
    "df.Age = df.Age.apply(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select ther 80% of the set randomly as our train set and 20% as our test set\n",
    "df_train = df.sample(frac=.8)\n",
    "df_test = df[~ df.index.isin(df_train.index)]\n",
    "\n",
    "# We divide info from classification and data\n",
    "df_train_class = df_train.Survived.to_numpy()\n",
    "df_train_data = df_train.drop(['Survived'], axis=1).to_numpy(dtype=np.float64)\n",
    "df_test_class = df_test.Survived.to_numpy()\n",
    "df_test_data = df_test.drop(['Survived'], axis=1).to_numpy(dtype=np.float64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test gave 72 correct prediction and 70 wrong prediction having a precision of 0.5070422535211268\n",
      "[-6.       4.6     -2.5     -4.8     -4.2     10.98212 -0.7    ]\n"
     ]
    }
   ],
   "source": [
    "# We train and test our perceptron\n",
    "perceptron = Perceptron(0.1, df.shape[1] - 1)\n",
    "perceptron.train(df_train_data, df_train_class)\n",
    "perceptron.test(df_test_data, df_test_class)\n",
    "print(perceptron.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Likely the perceptron is a unsufficient proposal for the analisys of this dataset given that this test when repeated multiple times havea big desviation in the possible results and only guess aorund 60% of the cases most time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complexity\n",
    "\n",
    "The perceptron algorithm have a complexity of O(n) in terms of the size of his train dataset, being a set of linear operations and comparisons in a n sized dataset, since the dot product is a linear combination simply."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
